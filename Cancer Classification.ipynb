{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerDataSet = pd.read_csv(\"BreastCancerWisconsinDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cancerDataSet['diagnosis'].map(lambda d: 1 if d == 'M' else 0).values\n",
    "X = cancerDataSet.drop(['diagnosis', 'id'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the input data into a training set and a test set\n",
    "m = X.shape[0]\n",
    "m_train = 400\n",
    "m_test = m - m_train\n",
    "\n",
    "X_train = X[:m_train]\n",
    "y_train = y[:m_train]\n",
    "\n",
    "X_test = X[m_train:]\n",
    "y_test = y[m_train:]\n",
    "\n",
    "# Gets a batch of the training data. \n",
    "# NOTE: Rather than loading a whole large data set as above and then taking array slices as done here, \n",
    "#       This method can connect to a data source and select just the batch needed.\n",
    "def get_training_batch(batch_num, batch_size):\n",
    "    lower = batch_num * (m_train // batch_size)\n",
    "    upper = lower + batch_size\n",
    "    return X_train[lower:upper], y_train[lower:upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Make this notebook's output stable across runs\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# A method to build a new neural net layer of a given size,  \n",
    "# fully connect it to a given preceding layer X, and \n",
    "# compute its output Z either with or without (default) an activation function\n",
    "# Call with activation=tf.nn.relu or tf.nn.sigmoid or tf.nn.tanh, for examples\n",
    "\n",
    "def make_nn_layer(layer_name, layer_size, X, activation=None):\n",
    "    with tf.name_scope(layer_name):\n",
    "        X_size = int(X.get_shape()[1])\n",
    "        SD = 2 / np.sqrt(X_size)\n",
    "        weights = tf.truncated_normal((X_size, layer_size), dtype=tf.float64, stddev=SD)\n",
    "        W = tf.Variable(weights, name='weights')\n",
    "        b = tf.Variable(tf.zeros([layer_size], dtype=tf.float64), name='biases')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Make the neural net structure\n",
    "n = int(X.shape[1])\n",
    "print(n)\n",
    "n_inputs = n\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 5\n",
    "n_outputs = 2   # Two output classes: malignant or non-malignant\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=(None, n_inputs), name='X')\n",
    "\n",
    "with tf.name_scope('nn'):\n",
    "    hidden1 = make_nn_layer('hidden1', n_hidden1, X, activation=tf.nn.relu)\n",
    "    hidden2 = make_nn_layer('hidden2', n_hidden2, hidden1, activation=tf.nn.relu)\n",
    "    outputs = make_nn_layer('outputs', n_outputs, hidden2) \n",
    "    outputs = tf.identity(outputs, \"nn_output\")\n",
    "    \n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how the neural net will learn\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=outputs)\n",
    "    loss = tf.reduce_mean(xentropy, name='l')\n",
    "    \n",
    "learning_rate = 0.0001\n",
    "with tf.name_scope(\"train\"):\n",
    "#    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"test\"):\n",
    "    correct = tf.nn.in_top_k(tf.cast(outputs, tf.float32), y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the ability to save and restore the trained neural net...\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Training accuracy: 0.5675 Testing accuracy: 0.7692308\n",
      "200 Training accuracy: 0.885 Testing accuracy: 0.70414203\n",
      "300 Training accuracy: 0.8925 Testing accuracy: 0.7692308\n",
      "400 Training accuracy: 0.895 Testing accuracy: 0.7692308\n",
      "500 Training accuracy: 0.9125 Testing accuracy: 0.7751479\n",
      "600 Training accuracy: 0.9125 Testing accuracy: 0.7751479\n",
      "700 Training accuracy: 0.9125 Testing accuracy: 0.7810651\n",
      "800 Training accuracy: 0.9175 Testing accuracy: 0.7810651\n",
      "900 Training accuracy: 0.92 Testing accuracy: 0.7810651\n",
      "1000 Training accuracy: 0.92 Testing accuracy: 0.7810651\n",
      "\n",
      "Actual classes:    [1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0\n",
      " 0 0 0]\n",
      "Predicted classes: [1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING TIME\n",
    "\n",
    "# This is how many times to use the full set of training data\n",
    "n_epochs = 1000\n",
    "\n",
    "# For a larger training set, it's typically necessary to break training into\n",
    "# batches so only the memory needed to store one batch of training data is used\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as training_session:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Loop through the whole training set in batches\n",
    "        for batch_num in range(m_train // batch_size):\n",
    "            X_batch, y_batch = get_training_batch(batch_num, batch_size)\n",
    "            training_session.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "        if epoch % 100 == 99:\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch+1, \"Training accuracy:\", acc_train, \"Testing accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(training_session, \".\\CancerNN\")\n",
    "    \n",
    "    # A quick test with the trained model \n",
    "    Z = outputs.eval(feed_dict={X: X_test[:40]})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    print(\"\")\n",
    "    print(\"Actual classes:   \", y_test[:40])  \n",
    "    print(\"Predicted classes:\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 30)\n",
      "(400,)\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "1\n",
      "[1.245e+01 1.570e+01 8.257e+01 4.771e+02 1.278e-01 1.700e-01 1.578e-01\n",
      " 8.089e-02 2.087e-01 7.613e-02 3.345e-01 8.902e-01 2.217e+00 2.719e+01\n",
      " 7.510e-03 3.345e-02 3.672e-02 1.137e-02 2.165e-02 5.082e-03 1.547e+01\n",
      " 2.375e+01 1.034e+02 7.416e+02 1.791e-01 5.249e-01 5.355e-01 1.741e-01\n",
      " 3.985e-01 1.244e-01]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_train[5])\n",
    "print(y_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GUILHAUMELeroy-Melin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_73 (InputLayer)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 2)                 62        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,852\n",
      "Trainable params: 2,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 360 samples, validate on 40 samples\n",
      "Epoch 1/10\n",
      "360/360 [==============================] - 3s 8ms/step - loss: 3.7074 - acc: 0.6944 - val_loss: 1.5140 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "360/360 [==============================] - 0s 111us/step - loss: 1.1445 - acc: 0.8278 - val_loss: 1.5278 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "360/360 [==============================] - 0s 105us/step - loss: 1.0217 - acc: 0.8417 - val_loss: 1.5816 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "360/360 [==============================] - 0s 94us/step - loss: 1.0037 - acc: 0.8444 - val_loss: 1.4903 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "360/360 [==============================] - 0s 103us/step - loss: 0.9215 - acc: 0.8556 - val_loss: 1.3977 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "360/360 [==============================] - 0s 94us/step - loss: 0.8918 - acc: 0.8611 - val_loss: 1.3866 - val_acc: 0.8250\n",
      "Epoch 7/10\n",
      "360/360 [==============================] - 0s 108us/step - loss: 0.8776 - acc: 0.8611 - val_loss: 1.3890 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "360/360 [==============================] - 0s 103us/step - loss: 0.8662 - acc: 0.8611 - val_loss: 1.3075 - val_acc: 0.8750\n",
      "Epoch 9/10\n",
      "360/360 [==============================] - 0s 100us/step - loss: 0.9343 - acc: 0.8500 - val_loss: 1.3885 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "360/360 [==============================] - 0s 103us/step - loss: 0.8428 - acc: 0.8639 - val_loss: 1.6045 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "Inputs = Input(shape=(30,))\n",
    "Dense_1 = Dense(30)(Inputs)\n",
    "Dense_2 = Dense(30, activation=\"relu\")(Dense_1)\n",
    "Dense_3 = Dense(30, activation=\"relu\")(Dense_2)\n",
    "Dense_4 = Dense(2, activation=\"linear\")(Dense_3)\n",
    "Classifier = Activation('softmax')(Dense_4)\n",
    "\n",
    "model = Model(input=Inputs, output=Classifier)\n",
    "model.summary()\n",
    "\n",
    "#optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
    "optimizer = RMSprop(lr=0.0001)\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 0s 71us/step\n",
      "Test accuracy: 0.62721893032627\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    " \n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
